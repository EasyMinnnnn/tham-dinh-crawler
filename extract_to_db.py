import os
import sys
import json
import re
from typing import List, Dict, Tuple, Optional

from google.cloud import documentai_v1 as documentai
from google.oauth2 import service_account
from google.api_core.exceptions import GoogleAPICallError
from google.protobuf.json_format import MessageToDict

# DB helpers
from src.db import get_conn, init_schema

os.makedirs("preprocessed", exist_ok=True)

# ---------- Load Document AI credentials ----------
credentials_json = os.environ.get("GOOGLE_APPLICATION_CREDENTIALS_JSON")
if not credentials_json:
    print("âŒ Thiáº¿u biáº¿n GOOGLE_APPLICATION_CREDENTIALS_JSON.")
    sys.exit(1)

try:
    credentials_dict = json.loads(credentials_json)
    credentials = service_account.Credentials.from_service_account_info(credentials_dict)
except Exception as e:
    print(f"âŒ GOOGLE_APPLICATION_CREDENTIALS_JSON khÃ´ng há»£p lá»‡: {e}")
    sys.exit(1)

project_id = os.environ.get("GOOGLE_PROJECT_ID")
processor_id = os.environ.get("GOOGLE_PROCESSOR_ID")            # Form Parser
processor_id_ocr = os.environ.get("GOOGLE_PROCESSOR_ID_OCR")    # Document OCR
location = os.environ.get("GOOGLE_LOCATION", "us")

if not project_id or not processor_id or not processor_id_ocr:
    print("âŒ Thiáº¿u GOOGLE_PROJECT_ID hoáº·c PROCESSOR_ID hoáº·c PROCESSOR_ID_OCR.")
    sys.exit(1)

client = documentai.DocumentProcessorServiceClient(credentials=credentials)
name_form_parser = f"projects/{project_id}/locations/{location}/processors/{processor_id}"
name_doc_ocr     = f"projects/{project_id}/locations/{location}/processors/{processor_id_ocr}"

# ---------- Small utils ----------
def extract_text(text_anchor, text):
    if not text_anchor.text_segments:
        return ""
    result = ""
    for segment in text_anchor.text_segments:
        start = segment.start_index if segment.start_index else 0
        end = segment.end_index
        result += text[start:end]
    return result.strip()

def extract_tables(document) -> List[List[List[str]]]:
    """Return list of tables; each table is list of rows; row is list of cell strings."""
    out = []
    text = document.text
    for page in document.pages:
        for table in page.tables:
            rows = []
            for row in list(table.header_rows) + list(table.body_rows):
                cells = []
                for cell in row.cells:
                    cells.append(extract_text(cell.layout.text_anchor, text))
                rows.append(cells)
            out.append(rows)
    return out

def safe_lower(s: Optional[str]) -> str:
    return (s or "").strip().lower()

# ---------- OCR free-text to get metadata ----------
def extract_meta_from_ocr(pdf_bytes: bytes) -> Tuple[str, str, str]:
    """
    Return (company_name, doc_no, signed_at)
    """
    try:
        raw_document = documentai.RawDocument(content=pdf_bytes, mime_type="application/pdf")
        request = documentai.ProcessRequest(name=name_doc_ocr, raw_document=raw_document)
        result = client.process_document(request=request)
        text = result.document.text

        # CÃ´ng ty ... (â€¦TÄG/TDG)
        company_match = re.search(r"(CÃ´ng\s*ty[\s\S]{0,200}?\([^\)]+T[ÄD]G\))", text, re.IGNORECASE)
        company_name = company_match.group(1).strip() if company_match else ""

        # Sá»‘ hiá»‡u vÄƒn báº£n dáº¡ng 123/TB-BTC
        docno_match = re.search(r"(\d{2,5}\s*/\s*TB-BTC)", text, re.IGNORECASE)
        doc_no = docno_match.group(1).replace(" ", "") if docno_match else ""

        # â€œThá»i gian kÃ½:â€ hoáº·c â€œNgÃ y kÃ½:â€
        time_match = re.search(r"(Thá»i\s*gian\s*kÃ½|NgÃ y\s*kÃ½)[:\s]+([^\n]+)", text, re.IGNORECASE)
        signed_at = time_match.group(2).strip() if time_match else ""

        return company_name, doc_no, signed_at
    except Exception as e:
        print(f"âš ï¸ Lá»—i OCR meta: {e}")
        return "", "", ""

# ---------- Map headers to indices flexibly ----------
PERSONAL_HEADER_CANDIDATES = {
    "full_name": ["tháº©m Ä‘á»‹nh viÃªn", "há» tÃªn", "há» vÃ  tÃªn"],
    "card_no":   ["sá»‘ tháº»", "sothe", "sá»‘ tháº» tdv"],
    "position":  ["chá»©c danh", "chá»©c danh Ä‘Äƒng kÃ½ hÃ nh nghá»", "chá»©c danh Ä‘Äƒng ky hanh nghe"],
    "valid_from":["ngÃ y hiá»‡u lá»±c", "ká»ƒ tá»« ngÃ y", "ke tu ngay"],
}

def map_header_indices(header_row: List[str]) -> Dict[str, int]:
    idx = {}
    lower = [safe_lower(x) for x in header_row]
    for key, cands in PERSONAL_HEADER_CANDIDATES.items():
        for cand in cands:
            for j, cell in enumerate(lower):
                if cand in cell:
                    idx[key] = j
                    break
            if key in idx:
                break
    return idx

# ---------- Write to DB ----------
def upsert_personal(record: Dict[str, str]) -> None:
    """
    record keys: card_no, full_name, position, company, valid_from, doc_no, signed_at, source_url
    """
    with get_conn() as conn:
        conn.execute("""
        INSERT INTO personal_records(card_no, full_name, position, company, valid_from, doc_no, signed_at, source_url)
        VALUES (:card_no,:full_name,:position,:company,:valid_from,:doc_no,:signed_at,:source_url)
        ON CONFLICT(card_no) DO UPDATE SET
            full_name = excluded.full_name,
            position  = excluded.position,
            company   = excluded.company,
            valid_from= excluded.valid_from,
            doc_no    = excluded.doc_no,
            signed_at = excluded.signed_at,
            source_url= excluded.source_url,
            updated_at= CURRENT_TIMESTAMP
        """, record)

# ---------- Main processing ----------
def process_file(pdf_path: str) -> bool:
    init_schema()
    json_path = pdf_path.replace(".pdf", ".json")
    print(f"\nğŸ“„ Äang xá»­ lÃ½ file: {pdf_path}")

    source_url = os.environ.get("CURRENT_SOURCE_URL", "")

    try:
        with open(pdf_path, "rb") as f:
            pdf_bytes = f.read()

        # 1) Meta tá»« OCR vÄƒn báº£n tá»± do
        company_name, doc_no, signed_at = extract_meta_from_ocr(pdf_bytes)

        # 2) Form Parser Ä‘á»ƒ láº¥y báº£ng
        raw_document = documentai.RawDocument(content=pdf_bytes, mime_type="application/pdf")
        request = documentai.ProcessRequest(name=name_form_parser, raw_document=raw_document)
        result = client.process_document(request=request)
        document = result.document

        if not document.text.strip():
            print(f"âš ï¸ KhÃ´ng cÃ³ vÄƒn báº£n OCR Ä‘Æ°á»£c tá»«: {pdf_path}")
            return False

        # LÆ°u JSON gá»‘c (debug)
        try:
            document_dict = MessageToDict(document._pb, preserving_proto_field_name=True)
            with open(json_path, "w", encoding="utf-8") as f:
                json.dump(document_dict, f, ensure_ascii=False, indent=2)
            print(f"âœ… ÄÃ£ lÆ°u file JSON: {json_path}")
        except Exception as _:
            pass

        tables = extract_tables(document)
        if not tables:
            print("âš ï¸ KhÃ´ng phÃ¡t hiá»‡n báº£ng.")
            return False

        # Láº¥y báº£ng Ä‘áº§u tiÃªn cÃ³ header phÃ¹ há»£p
        used_any_row = False
        for table in tables:
            if not table or len(table) < 2:
                continue
            header = table[0]
            idx_map = map_header_indices(header)
            if "card_no" not in idx_map or "full_name" not in idx_map:
                continue  # khÃ´ng Ä‘Ãºng dáº¡ng mong muá»‘n

            for row in table[1:]:
                # chá»‘ng index out of range náº¿u hÃ ng thiáº¿u Ã´
                def get(i): 
                    return row[i].strip() if i < len(row) else ""

                rec = {
                    "card_no":   get(idx_map.get("card_no", -1)),
                    "full_name": get(idx_map.get("full_name", -1)),
                    "position":  get(idx_map.get("position", -1)),
                    "company":   company_name,
                    "valid_from":get(idx_map.get("valid_from", -1)),
                    "doc_no":    doc_no,
                    "signed_at": signed_at,
                    "source_url": source_url,
                }
                # bá» qua dÃ²ng rá»—ng/khÃ´ng cÃ³ sá»‘ tháº»
                if not rec["card_no"] and not rec["full_name"]:
                    continue
                upsert_personal(rec)
                used_any_row = True

        if used_any_row:
            print("ğŸ’¾ ÄÃ£ ghi/ cáº­p nháº­t dá»¯ liá»‡u vÃ o SQLite (personal_records).")
            try:
                os.remove(pdf_path)
            except Exception:
                pass
            return True

        print("âš ï¸ KhÃ´ng cÃ³ dÃ²ng há»£p lá»‡ Ä‘á»ƒ ghi.")
        return False

    except GoogleAPICallError as api_error:
        print(f"âŒ Lá»—i tá»« Google API: {api_error}")
    except Exception as e:
        print(f"âŒ Lá»—i khi xá»­ lÃ½ {pdf_path}: {e}")
    return False

if __name__ == "__main__":
    input_dir = "outputs"
    os.makedirs(input_dir, exist_ok=True)
    files = [f for f in os.listdir(input_dir) if f.endswith(".pdf")]
    success = 0
    for f in files:
        path = os.path.join(input_dir, f)
        if process_file(path):
            success += 1
    print(f"\nğŸ“Š Tá»•ng sá»‘ file Ä‘Ã£ xá»­ lÃ½ thÃ nh cÃ´ng: {success}")
