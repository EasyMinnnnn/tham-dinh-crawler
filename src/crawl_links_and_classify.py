import os
import json
import re
from playwright.sync_api import sync_playwright
from googleapiclient.discovery import build
from google.oauth2.service_account import Credentials

# ============ CONFIG ============
BASE_URL   = "https://mof.gov.vn"
START_PATH = "/bo-tai-chinh/danh-sach-tham-dinh-ve-gia"
FULL_URL   = BASE_URL + START_PATH

# NƒÉm crawl (m·∫∑c ƒë·ªãnh 2025)
YEAR = int(os.getenv("CRAWL_YEAR", "2025"))

# T√™n tab ƒë√≠ch
SHEET_TAB_PERSONAL = os.getenv("SHEET_TAB_PERSONAL", "Personal")
SHEET_TAB_COMPANY  = os.getenv("SHEET_TAB_COMPANY",  "Company")

# T·ª´ kh√≥a ph√¢n lo·∫°i
KW_PERSONAL = [
    "danh s√°ch th·∫©m ƒë·ªãnh vi√™n v·ªÅ gi√°",
    "ƒëi·ªÅu ch·ªânh th√¥ng tin v·ªÅ th·∫©m ƒë·ªãnh vi√™n",
]
KW_COMPANY = ["thu h·ªìi", "ƒë√¨nh ch·ªâ", "quy·∫øt ƒë·ªãnh"]

# ============ GOOGLE SHEETS ============
sheet_json = os.environ.get("GOOGLE_CREDENTIALS_JSON")
sheet_id   = os.environ.get("GOOGLE_SHEET_ID")

if not sheet_json or not sheet_id:
    print("‚ùå Thi·∫øu GOOGLE_CREDENTIALS_JSON ho·∫∑c GOOGLE_SHEET_ID.")
    raise SystemExit(1)

creds_dict = json.loads(sheet_json)
creds = Credentials.from_service_account_info(creds_dict)
service = build("sheets", "v4", credentials=creds)
sheet = service.spreadsheets()

# ============ HELPERS ============
def _normalize(s: str) -> str:
    return (s or "").strip().lower()

def is_target_year(title: str, href: str) -> bool:
    """
    ∆Øu ti√™n l·ªçc theo '2025' trong ti√™u ƒë·ªÅ; n·∫øu kh√¥ng c√≥ th√¨ fallback theo URL.
    C√≥ th·ªÉ m·ªü r·ªông n·∫øu MOF thay ƒë·ªïi m·∫´u ti√™u ƒë·ªÅ.
    """
    t = _normalize(title)
    if str(YEAR) in t:
        return True
    return str(YEAR) in _normalize(href)

def classify_bucket(title: str) -> str | None:
    t = _normalize(title)
    if any(k in t for k in KW_PERSONAL):
        return "personal"
    if any(k in t for k in KW_COMPANY):
        return "company"
    return None

def write_to_sheet(target_tab: str, rows: list[list[str]]) -> None:
    if not rows:
        return
    sheet.values().update(
        spreadsheetId=sheet_id,
        range=f"{target_tab}!A2",
        valueInputOption="RAW",
        body={"values": rows},
    ).execute()
    print(f"üìÑ ƒê√£ ghi {len(rows)} link v√†o sheet '{target_tab}'.")

# ============ MAIN ============
def crawl_links_and_classify():
    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        page = browser.new_page()
        try:
            print(f"üåê ƒêang m·ªü trang: {FULL_URL}")
            page.goto(FULL_URL, timeout=60000)
            page.wait_for_timeout(5000)  # ch·ªù JS load

            elements = page.query_selector_all("a")
            print(f"üîó T·ªïng s·ªë th·∫ª <a>: {len(elements)}")

            personal_rows: list[list[str]] = []
            company_rows: list[list[str]] = []
            seen_links: set[str] = set()

            for el in elements:
                href = el.get_attribute("href")
                if not href or not href.startswith(START_PATH + "/"):
                    continue

                title = (el.inner_text() or "").strip()
                if not title:
                    continue

                # L·ªçc theo nƒÉm
                if not is_target_year(title, href):
                    continue

                bucket = classify_bucket(title)
                if not bucket:
                    continue

                full_link = BASE_URL + href

                # Ch·ªëng tr√πng URL
                if full_link in seen_links:
                    continue
                seen_links.add(full_link)

                row = [title, full_link]
                if bucket == "personal":
                    personal_rows.append(row)
                else:
                    company_rows.append(row)

        finally:
            browser.close()

        if not personal_rows and not company_rows:
            print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y link ph√π h·ª£p (nƒÉm/keywords).")
            return

        print(f"‚úÖ Link h·ª£p l·ªá: C√° nh√¢n={len(personal_rows)} | Doanh nghi·ªáp={len(company_rows)}")
        write_to_sheet(SHEET_TAB_PERSONAL, personal_rows)
        write_to_sheet(SHEET_TAB_COMPANY,  company_rows)

if __name__ == "__main__":
    crawl_links_and_classify()
