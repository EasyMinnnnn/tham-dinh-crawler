import os
import json
import requests
from bs4 import BeautifulSoup
import gspread
from google.oauth2.service_account import Credentials

def crawl_new_links():
    url = "https://mof.gov.vn/bo-tai-chinh/danh-sach-tham-dinh-ve-gia"
    res = requests.get(url, timeout=10)
    soup = BeautifulSoup(res.text, "html.parser")

    base = "https://mof.gov.vn"
    found = []

    for a in soup.find_all("a", href=True):
        href = a["href"].strip()
        title = a.get_text(strip=True)

        # Lá»c Ä‘Ãºng link con vÃ  cÃ³ tiÃªu Ä‘á»
        if href.startswith("/bo-tai-chinh/danh-sach-tham-dinh-ve-gia/") and title:
            full_url = base + href
            found.append({"title": title, "link": full_url})

    print(f"ğŸ” ÄÃ£ tÃ¬m tháº¥y {len(found)} link phÃ¹ há»£p.")
    return found

def write_to_google_sheet(new_items):
    # XÃ¡c thá»±c Google Sheets
    creds_json = os.environ["GOOGLE_CREDENTIALS_JSON"]
    creds_dict = json.loads(creds_json)
    scope = ["https://www.googleapis.com/auth/spreadsheets"]
    creds = Credentials.from_service_account_info(creds_dict, scopes=scope)
    client = gspread.authorize(creds)

    # Má»Ÿ sheet Ä‘áº§u tiÃªn (sheet1)
    sheet = client.open_by_key(os.environ["GOOGLE_SHEET_ID"]).sheet1

    # Láº¥y danh sÃ¡ch link Ä‘Ã£ cÃ³ (cá»™t B)
    existing_links = set(sheet.col_values(2))

    count_new = 0
    for item in reversed(new_items):  # Giá»¯ thá»© tá»± má»›i nháº¥t lÃªn Ä‘áº§u
        if item["link"] not in existing_links:
            sheet.insert_row([item["title"], item["link"]], 1)
            print("âœ… ÄÃ£ thÃªm:", item["title"])
            count_new += 1

    print("ğŸ§¾ Tá»•ng sá»‘ dÃ²ng má»›i:", count_new)

if __name__ == "__main__":
    try:
        items = crawl_new_links()
        write_to_google_sheet(items)
    except Exception as e:
        print("âŒ Lá»—i khi xá»­ lÃ½:", e)
