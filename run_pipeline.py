import os
import sys
import sqlite3
import subprocess
from pathlib import Path
from typing import List, Tuple

# ======== CONFIG ========
CRAWL_YEAR = int(os.getenv("CRAWL_YEAR", "2025"))
OUTPUT_DIR = "outputs"
PIPELINE_LIMIT = int(os.getenv("PIPELINE_LIMIT", "5"))

# Paths
ROOT = Path(__file__).resolve().parent                       # repo root
DB_PATH = ROOT / "data.db"
CRAWLER = ROOT / "src" / "crawl_links_and_classify.py"       # trong src
DOWNLOADER = ROOT / "download_pdf.py"                         # ·ªü TH∆Ø M·ª§C G·ªêC
EXTRACTOR = ROOT / "src" / "extract_to_db.py"                 # trong src

def run_cmd(args: list[str], env=None) -> subprocess.CompletedProcess:
    """Run a command using the same Python interpreter + repo root cwd."""
    return subprocess.run([sys.executable] + [str(a) for a in args],
                          cwd=str(ROOT),
                          env=env or os.environ.copy(),
                          text=True,
                          capture_output=False,
                          check=True)

def fetch_personal_links(year: int, limit: int) -> List[Tuple[str, str]]:
    if not DB_PATH.exists():
        return []
    conn = sqlite3.connect(str(DB_PATH))
    try:
        cur = conn.cursor()
        cur.execute(
            """
            SELECT title, url
            FROM links
            WHERE year = ? AND bucket = 'personal'
            ORDER BY id DESC
            LIMIT ?
            """,
            (year, limit),
        )
        rows = cur.fetchall()
        return [(r[0], r[1]) for r in rows]
    finally:
        conn.close()

# ======== 1) RUN CRAWLER ========
print("üöÄ ƒêang crawl link m·ªõi b·∫±ng Playwright (ghi v√†o SQLite)‚Ä¶")
try:
    run_cmd([CRAWLER])
except subprocess.CalledProcessError as e:
    print(f"‚ö†Ô∏è Crawler l·ªói (ti·∫øp t·ª•c pipeline): {e}")

# ======== 2) L·∫§Y LINK 'C√Å NH√ÇN' NƒÇM 2025 T·ª™ DB ========
links = fetch_personal_links(CRAWL_YEAR, PIPELINE_LIMIT)
print(f"üîó S·∫Ω x·ª≠ l√Ω {len(links)} link 'C√° nh√¢n' (nƒÉm {CRAWL_YEAR})")

os.makedirs(ROOT / OUTPUT_DIR, exist_ok=True)

# ======== 3) V√íNG L·∫∂P: DOWNLOAD ‚Üí OCR+PARSE+UPSERT DB ========
for idx, (title, url) in enumerate(links, 1):
    print(f"\nüü° [{idx}] {title}")
    try:
        print("‚¨áÔ∏è  ƒêang t·∫£i PDF‚Ä¶")
        run_cmd([DOWNLOADER, url])

        # Truy·ªÅn ngu·ªìn cho extractor ghi v√†o DB
        env = os.environ.copy()
        env["CURRENT_SOURCE_URL"] = url

        print("üß†  OCR & parse & ghi DB‚Ä¶")
        run_cmd([EXTRACTOR], env=env)

        # Xo√° PDF c√≤n s√≥t (extractor ƒë√£ xo√° khi th√†nh c√¥ng)
        for f in (ROOT / OUTPUT_DIR).glob("*.pdf"):
            try:
                f.unlink(missing_ok=True)
            except Exception:
                pass

        print("‚úÖ Ho√†n t·∫•t 1 link.")
    except subprocess.CalledProcessError as e:
        print(f"‚ùå L·ªói khi x·ª≠ l√Ω: {e}")

print("\nüéâ Pipeline k·∫øt th√∫c.")
