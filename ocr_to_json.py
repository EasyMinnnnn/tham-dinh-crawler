import os
import sys
import json
import re
from typing import List, Dict, Any, Tuple, Optional

from google.cloud import documentai_v1 as documentai
from google.oauth2 import service_account
from google.api_core.exceptions import GoogleAPICallError
from google.protobuf.json_format import MessageToDict

# Th∆∞ m·ª•c I/O
INPUT_DIR = "outputs"
RAW_JSON_DIR = "preprocessed"     # dump JSON g·ªëc t·ª´ Document AI (debug)
OUT_JSON_DIR = "outputs_json"     # JSON chu·∫©n ho√° ƒë·ªÉ c√°c b∆∞·ªõc sau d√πng

os.makedirs(RAW_JSON_DIR, exist_ok=True)
os.makedirs(OUT_JSON_DIR, exist_ok=True)

# ---------- Load Document AI credentials ----------
credentials_json = os.environ.get("GOOGLE_APPLICATION_CREDENTIALS_JSON")
if not credentials_json:
    print("‚ùå Thi·∫øu bi·∫øn GOOGLE_APPLICATION_CREDENTIALS_JSON.")
    sys.exit(1)

try:
    credentials_dict = json.loads(credentials_json)
    credentials = service_account.Credentials.from_service_account_info(credentials_dict)
except Exception as e:
    print(f"‚ùå GOOGLE_APPLICATION_CREDENTIALS_JSON kh√¥ng h·ª£p l·ªá: {e}")
    sys.exit(1)

project_id      = os.environ.get("GOOGLE_PROJECT_ID")
processor_id    = os.environ.get("GOOGLE_PROCESSOR_ID")         # Form Parser
processor_id_ocr= os.environ.get("GOOGLE_PROCESSOR_ID_OCR")     # Document OCR
location        = os.environ.get("GOOGLE_LOCATION", "us")

if not project_id or not processor_id or not processor_id_ocr:
    print("‚ùå Thi·∫øu GOOGLE_PROJECT_ID ho·∫∑c PROCESSOR_ID ho·∫∑c PROCESSOR_ID_OCR.")
    sys.exit(1)

client = documentai.DocumentProcessorServiceClient(credentials=credentials)
NAME_FORM  = f"projects/{project_id}/locations/{location}/processors/{processor_id}"
NAME_OCR   = f"projects/{project_id}/locations/{location}/processors/{processor_id_ocr}"

# ---------- Utils ----------
def _safe(s: Optional[str]) -> str:
    return (s or "").strip()

def _lower(s: Optional[str]) -> str:
    return (s or "").strip().lower()

def extract_text(text_anchor, full_text: str) -> str:
    if not text_anchor or not text_anchor.text_segments:
        return ""
    result = []
    for seg in text_anchor.text_segments:
        start = seg.start_index if seg.start_index else 0
        end = seg.end_index
        result.append(full_text[start:end])
    return "".join(result).strip()

def extract_tables(document: documentai.Document) -> List[List[List[str]]]:
    """Tr·∫£ v·ªÅ list c√°c b·∫£ng; m·ªói b·∫£ng l√† list row; row l√† list cell text."""
    out: List[List[List[str]]] = []
    full_text = document.text
    for page in document.pages:
        for table in page.tables:
            rows: List[List[str]] = []
            for row in list(table.header_rows) + list(table.body_rows):
                cells = []
                for cell in row.cells:
                    cells.append(extract_text(cell.layout.text_anchor, full_text))
                rows.append(cells)
            out.append(rows)
    return out

# ---------- OCR free-text ƒë·ªÉ l·∫•y meta ----------
def extract_meta_from_ocr(pdf_bytes: bytes) -> Tuple[str, str, str]:
    """
    Return (company_name, doc_no, signed_at)
    - company_name: "C√¥ng ty ... (xxTƒêG)" ho·∫∑c t∆∞∆°ng t·ª±
    - doc_no:       "123/TB-BTC" (cho ph√©p c√≥ kho·∫£ng tr·∫Øng 2 b√™n d·∫•u '/')
    - signed_at:    d√≤ng sau 'Th·ªùi gian k√Ω:' ho·∫∑c 'Ng√†y k√Ω:'
    """
    try:
        raw = documentai.RawDocument(content=pdf_bytes, mime_type="application/pdf")
        req = documentai.ProcessRequest(name=NAME_OCR, raw_document=raw)
        result = client.process_document(request=req)
        text = result.document.text or ""

        # C√¥ng ty ... (‚Ä¶TƒêG/TDG)
        company = ""
        m_comp = re.search(r"(C√¥ng\s*ty[\s\S]{0,200}?\([^)]+T[ƒêD]G\))", text, re.IGNORECASE)
        if m_comp:
            company = m_comp.group(1).strip()

        # S·ªë hi·ªáu 123/TB-BTC (cho ph√©p c√≥ kho·∫£ng tr·∫Øng quanh '/')
        doc_no = ""
        m_doc = re.search(r"(\d{2,5}\s*/\s*TB-BTC)", text, re.IGNORECASE)
        if m_doc:
            doc_no = m_doc.group(1).replace(" ", "")

        # ‚ÄúTh·ªùi gian k√Ω:‚Äù ho·∫∑c ‚ÄúNg√†y k√Ω:‚Äù
        signed_at = ""
        m_time = re.search(r"(Th·ªùi\s*gian\s*k√Ω|Ng√†y\s*k√Ω)[:\s]+([^\n]+)", text, re.IGNORECASE)
        if m_time:
            signed_at = m_time.group(2).strip()

        return company, doc_no, signed_at
    except Exception as e:
        print(f"‚ö†Ô∏è L·ªói OCR meta: {e}")
        return "", "", ""

# ---------- Form Parser ----------
def form_parse(pdf_bytes: bytes) -> documentai.Document:
    raw = documentai.RawDocument(content=pdf_bytes, mime_type="application/pdf")
    req = documentai.ProcessRequest(name=NAME_FORM, raw_document=raw)
    return client.process_document(request=req).document

# ---------- Ghi JSON chu·∫©n ----------
def write_normalized_json(out_path: str, payload: Dict[str, Any]) -> None:
    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(payload, f, ensure_ascii=False, indent=2)

# ---------- Pipeline 1 file ----------
def process_file(pdf_path: str) -> bool:
    print(f"\nüìÑ ƒêang x·ª≠ l√Ω file: {pdf_path}")
    base = os.path.splitext(os.path.basename(pdf_path))[0]
    raw_json_path = os.path.join(RAW_JSON_DIR, base + ".documentai.json")
    out_json_path = os.path.join(OUT_JSON_DIR, base + ".json")

    # C√≥ th·ªÉ set t·ª´ caller ƒë·ªÉ l∆∞u ngu·ªìn link
    source_url = os.environ.get("CURRENT_SOURCE_URL", "")

    try:
        with open(pdf_path, "rb") as f:
            pdf_bytes = f.read()

        # 1) L·∫•y meta t·ª± do t·ª´ OCR
        company_name, doc_no, signed_at = extract_meta_from_ocr(pdf_bytes)

        # 2) Form Parser ƒë·ªÉ l·∫•y b·∫£ng
        document = form_parse(pdf_bytes)
        if not (document.text or "").strip():
            print("‚ö†Ô∏è Document AI kh√¥ng tr·∫£ v·ªÅ vƒÉn b·∫£n.")
            return False

        # Dump JSON g·ªëc ƒë·ªÉ debug (kh√¥ng b·∫Øt bu·ªôc)
        try:
            doc_dict = MessageToDict(document._pb, preserving_proto_field_name=True)
            with open(raw_json_path, "w", encoding="utf-8") as f:
                json.dump(doc_dict, f, ensure_ascii=False, indent=2)
            print(f"üìù ƒê√£ l∆∞u JSON g·ªëc: {raw_json_path}")
        except Exception:
            pass

        tables = extract_tables(document)

        # 3) JSON chu·∫©n ho√° cho b∆∞·ªõc sau (ghi DB/hi·ªÉn th·ªã)
        normalized = {
            "pdf_name": os.path.basename(pdf_path),
            "source_url": source_url,
            "company_name": company_name,
            "doc_no": doc_no,
            "signed_at": signed_at,
            "tables": tables,  # list[table] -> table: list[row] -> row: list[cells]
            "raw_documentai_json_path": raw_json_path,
        }
        write_normalized_json(out_json_path, normalized)
        print(f"‚úÖ ƒê√£ l∆∞u JSON chu·∫©n: {out_json_path}")

        # Kh√¥ng c√≤n push l√™n Google Sheet; ƒë·ªÉ file JSON cho b∆∞·ªõc k·∫ø ti·∫øp d√πng
        try:
            os.remove(pdf_path)
        except Exception:
            pass
        return True

    except GoogleAPICallError as api_error:
        print(f"‚ùå L·ªói t·ª´ Google API: {api_error}")
    except Exception as e:
        print(f"‚ùå L·ªói khi x·ª≠ l√Ω {pdf_path}: {e}")
    return False

# ---------- Entry ----------
if __name__ == "__main__":
    os.makedirs(INPUT_DIR, exist_ok=True)
    files = [f for f in os.listdir(INPUT_DIR) if f.lower().endswith(".pdf")]
    success = 0
    for f in files:
        if process_file(os.path.join(INPUT_DIR, f)):
            success += 1
    print(f"\nüìä T·ªïng s·ªë file ƒë√£ x·ª≠ l√Ω th√†nh c√¥ng: {success}")
